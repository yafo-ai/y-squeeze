## 功能介绍

Y-Squeeze 主要是一个研究模型内部状态的框架，这也是我们经常用来分析模型注意力分配、训练效果的工具。

### 主要功能：

#### 1. 注意力分数

分析模型内部运行时的注意力分数，是理解模型内部状态的重要步骤。

此功能可以查看模型输入输出直接，每个token的注意力在哪里，以及对其他token的注意力分数。

注意力机制研究的论文有很多，但是我们第一版的源码，借鉴了北京师范大学的代码：https://github.com/CapitalCode2020/InfiniRetri2

在这里感谢你们所作的工作，同时也希望你们在新的理论研究项目中进展顺利！

注意：正式版将修复一些已知问题，并增加一些新功能。10月发布。

#### 2. token损失分析

通常这个功能是用来分析对比模型自身输出，和我们期望输出的loss差异。

#### 3. token熵分析

通常这个功能是用来分析模型训练之后的token的熵，来判断模型能力破坏的程度。

#### 4. 内容压缩（实验性质）

同第一点，但是在我们的实验环境中，效果不如预期，所以我们准备研究其他解决方案。

#### 5. 样本生成：自动生成样本

这部分功能本身和 Y-Trainer 的功能一致，放在本项目中是为了方便训练人员，临时查看预料生成的效果。

#### 6. 特征提取与聚类筛选：

通常K-means聚类的效果不是很理想。

本功能是，对多个文本进行特征提取后，利用K-means算法进行聚类。

通常提取特征使用的模型，需要和训练的模型使用同一个，因为模型认为是不是同一类的语料，通常和我们想的不一样。

#### 7. 预训练知识欠缺分析 此功能10月正式版开放

在垂直领域，我们如何才能知道模型对哪些知识不懂，或者比较模糊？

这个功能通过算法，可以识别出模型对哪些知识点概念模糊。

简单来说就是基座模型，在预训练的时候，相关知识点的语料过少，或者没有。

如果我们能分析出模型欠缺的知识点，那么我们就可以针对性的生产语料。


#### 8. 语料质量评分 此功能10月正式版开放

你在指令微调的时候是不是遇到过，一条有问题的语料导致模型能力被破坏？指令遵循能力大幅下降或者胡言乱语？

这个功能是为了解决以上问题的。

通过识别模型的推理参数，利用算法，对SFT语料进行质量评分，快速识别出有问题的语料。

评分都是基于要微调的模型来计算的。

有的时候，我们人类认为没有问题的语料，对于模型是有问题的。所以这个功能是很有帮助的。

同时由于可以对语料进行评分，我们可以对语料排序，由易到难的训练模型。
